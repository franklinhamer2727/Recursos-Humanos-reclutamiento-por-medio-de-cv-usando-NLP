{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PROCESO DE ANALISIS DE DATOS",
   "id": "9063e27eb51e717c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importacion de Librerias",
   "id": "99a39c6104c98032"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:51.702160Z",
     "start_time": "2024-05-02T01:29:51.556687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path"
   ],
   "id": "dd27af3405144dc9",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Funcion para convertir pdf en imagen",
   "id": "888ecb8bcd702c11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:52.203153Z",
     "start_time": "2024-05-02T01:29:52.191493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pdf_to_image(pdf_path, image_prefix):\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=300)\n",
    "        progress_bar = tqdm(total=len(images), desc=\"Convirtiendo páginas\")\n",
    "        for i, image in enumerate(images):\n",
    "            image_path = f\"{image_prefix}_page{i + 1}.jpg\"\n",
    "            image.save(image_path, 'JPEG')\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir el archivo: {pdf_path}\")\n",
    "        print(f\"Mensaje de error: {str(e)}\")"
   ],
   "id": "27c519cf639c9e75",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:52.444766Z",
     "start_time": "2024-05-02T01:29:52.437056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ejecutar_pdf_to_image(ruta_base_input, ruta_base_output):\n",
    "    for archivo in tqdm(os.listdir(ruta_base_input)):\n",
    "        if archivo.endswith('.pdf'):\n",
    "            nombre_archivo = os.path.splitext(archivo)[0]\n",
    "            carpeta_archivo = os.path.join(ruta_base_output, nombre_archivo) +'/'\n",
    "            os.makedirs(carpeta_archivo, exist_ok=True)\n",
    "            ruta_input = os.path.join(ruta_base_input, archivo)\n",
    "            pdf_to_image(ruta_input, carpeta_archivo)"
   ],
   "id": "b630fa86c719e366",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Rutas de archivos",
   "id": "221fa4b68bef656d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:52.878381Z",
     "start_time": "2024-05-02T01:29:52.866577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "ruta_pdf = \"../postulantes/pdf\"\n",
    "ruta_jpg = \"../postulantes/jpg/\"\n",
    "ruta_txt = \"../postulantes/txt/\"\n",
    "os.listdir(ruta_jpg)"
   ],
   "id": "313fe49c1db801e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['postulante1', 'postulante2', 'postulante3']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:53.184451Z",
     "start_time": "2024-05-02T01:29:53.144679Z"
    }
   },
   "cell_type": "code",
   "source": "ejecutar_pdf_to_image(ruta_pdf, ruta_jpg)",
   "id": "5c71dc5a4fd9b01f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 170.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al convertir el archivo: ../postulantes/pdf\\postulante1.pdf\n",
      "Mensaje de error: Unable to get page count. Is poppler installed and in PATH?\n",
      "Error al convertir el archivo: ../postulantes/pdf\\postulante2.pdf\n",
      "Mensaje de error: Unable to get page count. Is poppler installed and in PATH?\n",
      "Error al convertir el archivo: ../postulantes/pdf\\postulante3.pdf\n",
      "Mensaje de error: Unable to get page count. Is poppler installed and in PATH?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convertir JPG en formato Texto",
   "id": "6b68644a5b93f99e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importacion de librerias",
   "id": "450138024d60f0a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:55.139200Z",
     "start_time": "2024-05-02T01:29:54.404238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from pytesseract import image_to_string"
   ],
   "id": "57430e3e02650b92",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyarrow' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpytesseract\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m image_to_string\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pytesseract\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# flake8: noqa: F401\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytesseract\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ALTONotSupported\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytesseract\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_languages\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytesseract\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_tesseract_version\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pytesseract\\pytesseract.py:38\u001B[0m\n\u001B[0;32m     36\u001B[0m pandas_installed \u001B[38;5;241m=\u001B[39m find_loader(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpandas\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pandas_installed:\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m     40\u001B[0m DEFAULT_ENCODING \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     41\u001B[0m LANG_PATTERN \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m^[a-z_]+$\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:22\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# numpy compat\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_numpy_dev \u001B[38;5;28;01mas\u001B[39;00m _is_numpy_dev  \u001B[38;5;66;03m# pyright: ignore # noqa:F401\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hashtable \u001B[38;5;28;01mas\u001B[39;00m _hashtable, lib \u001B[38;5;28;01mas\u001B[39;00m _lib, tslib \u001B[38;5;28;01mas\u001B[39;00m _tslib\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py:22\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_typing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m F\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     19\u001B[0m     is_numpy_dev,\n\u001B[0;32m     20\u001B[0m     np_version_under1p21,\n\u001B[0;32m     21\u001B[0m )\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     23\u001B[0m     pa_version_under1p01,\n\u001B[0;32m     24\u001B[0m     pa_version_under2p0,\n\u001B[0;32m     25\u001B[0m     pa_version_under3p0,\n\u001B[0;32m     26\u001B[0m     pa_version_under4p0,\n\u001B[0;32m     27\u001B[0m     pa_version_under5p0,\n\u001B[0;32m     28\u001B[0m     pa_version_under6p0,\n\u001B[0;32m     29\u001B[0m     pa_version_under7p0,\n\u001B[0;32m     30\u001B[0m     pa_version_under8p0,\n\u001B[0;32m     31\u001B[0m     pa_version_under9p0,\n\u001B[0;32m     32\u001B[0m )\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlzma\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpa\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m     _pa_version \u001B[38;5;241m=\u001B[39m pa\u001B[38;5;241m.\u001B[39m__version__\n\u001B[0;32m     11\u001B[0m     _palv \u001B[38;5;241m=\u001B[39m Version(_pa_version)\n\u001B[0;32m     12\u001B[0m     pa_version_under1p01 \u001B[38;5;241m=\u001B[39m _palv \u001B[38;5;241m<\u001B[39m Version(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.0.1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'pyarrow' has no attribute '__version__'"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lectura_jpg_to_txt(ruta_jpg,ruta_txt,folder):\n",
    "    text = ''\n",
    "    if os.path.isdir(ruta_jpg):\n",
    "        print(f\"Archivos en la carpeta {folder}\")\n",
    "        for archivo in sorted(os.listdir(ruta_jpg)):\n",
    "            if archivo.endswith(\".jpg\"):\n",
    "                ruta_image = os.path.join(ruta_jpg,archivo)\n",
    "                # text = image_to_string(Image.open(ruta_image))\n",
    "                text += image_to_string(Image.open(ruta_image)) + '\\n'\n",
    "                \n",
    "    with open(ruta_txt, 'w') as file:\n",
    "        file.write(text)"
   ],
   "id": "72808c6b1b8029be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lectura_folder(ruta_jpg,ruta_txt):\n",
    "    for folder in os.listdir(ruta_jpg):\n",
    "        ruta_input_folder = os.path.join(ruta_jpg,folder) +'/'\n",
    "        output_file = os.path.join(ruta_txt,f'{folder}.txt')\n",
    "        \n",
    "        lectura_jpg_to_txt(ruta_input_folder,output_file,folder)"
   ],
   "id": "a49b040806176bdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lectura_folder(ruta_jpg,ruta_txt)",
   "id": "80adc50694699ed2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Separacion en bloques del curriculum segun los encabezados",
   "id": "8b75de55033dc0da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importacion de librerias",
   "id": "2abc88e0dd1081c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:55.720818Z",
     "start_time": "2024-05-02T01:29:55.713438Z"
    }
   },
   "cell_type": "code",
   "source": "import json",
   "id": "d3c10b50eba2af3b",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:55.965038Z",
     "start_time": "2024-05-02T01:29:55.956791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def leer_archivo(ruta_archivo):\n",
    "    with open(ruta_archivo,'r') as archivo:\n",
    "        contenido = archivo.read()\n",
    "    return contenido"
   ],
   "id": "5a8a01887ea8ae36",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:29:56.224130Z",
     "start_time": "2024-05-02T01:29:56.209295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def separar_bloques(texto):\n",
    "    informacion_personal = [\"Personal information\",\n",
    "                            \"Personal details\",\n",
    "                            \"Personal Profile\",\n",
    "                            \"Personal data\", \n",
    "                            \"Personal details\", \n",
    "                            \"Identity information\", \n",
    "                            \"Confidential information\", \n",
    "                            \"Private information\", \n",
    "                            \"Sensitive information\",\n",
    "                            \"Personal Dossier\",\n",
    "                            \"Resume\"]\n",
    "    \n",
    "    objetivos_profesionales = [\"Professional objectives\",\n",
    "                               \"Career aspirations\",\n",
    "                               \"Professional goal\",\n",
    "                               \"Occupational objectives\" \n",
    "                               \"Career goals\",\n",
    "                               \"Professional ambitions\",\n",
    "                               \"Professional summary\",\n",
    "                               \"Professional overview\",\n",
    "                               \"Work experience summary\",\n",
    "                               \"Career Objective\",\n",
    "                               \"Job target\",\"Goal\"]\n",
    "    experiencia_laboral = [\"Work experience\", \n",
    "                           \"Laboral experience\",\n",
    "                           \"Professional background\",\n",
    "                           \"Career history\",\n",
    "                           \"Professional experience\",\n",
    "                           \"Professional Trainings\",\n",
    "                           \"Job experience\",\n",
    "                           \"Employment record\",\n",
    "                           \"Employment history\",\n",
    "                           \"Working Experience\",\n",
    "                           \"Projects\",\n",
    "                           \"Experience\"]\n",
    "    education = [\"Education\",\n",
    "                 \"Academic and Professional\",\n",
    "                 \"academics\",\"ACADEMICS\",\n",
    "                 \"Academic background\",\n",
    "                 \"Educational history\", \n",
    "                 \"Academic record\", \n",
    "                 \"Scholarly background\",\n",
    "                 \"Educational qualifications\",\n",
    "                 \"Educational credentials\", \n",
    "                 \"Academic qualifications\", \n",
    "                 \"Educational achievements\",\n",
    "                 \"Academic Qualification\",\n",
    "                 \"Educational Background\",\n",
    "                 \"Academic degree\",\n",
    "                 \"Educational degree\", \n",
    "                 \"Qualification\",\n",
    "                \"academic details\",\n",
    "                 \"Educational details\",\n",
    "                 \"Scholastics\",\n",
    "                 \"Academic information\", \n",
    "                 \"Schooling particulars\"]\n",
    "    habilidades = [\"Technical and personal skills\",\n",
    "                   \"Technical and personal competencies\",\n",
    "                   \"Technical Skills\",\n",
    "                   \"Technical and personal expertise\",\n",
    "                   \"Abilities\", \n",
    "                   \"Competencies\",\n",
    "                   \"Personality Traits\",\n",
    "                   \"Software Skill\",\n",
    "                   \"Technical Proficiency\",\n",
    "                  \"Skills\"]\n",
    "    logros_premios = [\"Achievements and awards\", \n",
    "                      \"Accomplishments and honors\", \n",
    "                      \"Recognition and accolades\"]\n",
    "    \n",
    "    actividades_extracurriculares = [\"Extracurricular activities\", \n",
    "                                     \"Extra Curricular Activities\",\n",
    "                                     \"Additional activities\",\n",
    "                                     \"Extra Curricular Activitis\",\n",
    "                                     \"Extra Co-Curricutar Activities\",\n",
    "                                     \"Non-academic involvement\"]\n",
    "    referencias = [\"References\", \n",
    "                   \"Referees\", \n",
    "                   \"Recommendations\",\n",
    "                   \"Other Information\"]\n",
    "    cv_titulos = [informacion_personal,objetivos_profesionales,experiencia_laboral,\n",
    "                  education,habilidades,logros_premios,actividades_extracurriculares,referencias]\n",
    "    cv_titulos_dict = {\n",
    "    'informacion_personal': informacion_personal,\n",
    "    'objetivos_profesionales': objetivos_profesionales,\n",
    "    'experiencia_laboral': experiencia_laboral,\n",
    "    'education':education,\n",
    "    'habilidades':habilidades,\n",
    "    'logros_premios':logros_premios,\n",
    "    'actividades_extracurriculares':actividades_extracurriculares,\n",
    "    'referencias'   :referencias\n",
    "    }\n",
    "    cadenas_cv = []\n",
    "    cadenas_pos = []\n",
    "    cadenas_name = []\n",
    "    for cv_titulos in cv_titulos_dict.keys():\n",
    "        for find in cv_titulos_dict[cv_titulos]:\n",
    "            numero = texto.count(find.lower())\n",
    "            if(numero!=0):\n",
    "                pass\n",
    "            if numero!=0 and numero <2:\n",
    "                pos_texto = texto.find(find.lower())\n",
    "                if pos_texto != -1:\n",
    "                    cadenas_cv.append(find.lower())\n",
    "                    cadenas_pos.append(pos_texto)\n",
    "                    cadenas_name.append(cv_titulos)\n",
    "                    break\n",
    "    diccionario = {\n",
    "        'cadenas_name': cadenas_name,\n",
    "        'cadenas_cv': cadenas_cv,\n",
    "        'cadenas_pos': cadenas_pos,\n",
    "    }\n",
    "    \n",
    "    json_data = {}\n",
    "\n",
    "    diccionario_ordenado = dict(sorted(zip( diccionario['cadenas_name'],diccionario['cadenas_pos']),key=lambda x: x[1]))\n",
    "    name_bloque = 'Introduccion'\n",
    "    posicion_inicial_text = 0\n",
    "    count = 0\n",
    "    for key, value  in list(diccionario_ordenado.items()):        \n",
    "        json_data[name_bloque] = texto[posicion_inicial_text:value]    \n",
    "        name_bloque = key\n",
    "        posicion_inicial_text = value\n",
    "        count +=1\n",
    "    json_data[name_bloque] = texto[posicion_inicial_text:len(texto)]\n",
    "    \n",
    "    return json.dumps(json_data)"
   ],
   "id": "b38114f2cc80ba82",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:17:47.574228Z",
     "start_time": "2024-05-02T03:17:47.568024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_doc_to_json(link_doc):\n",
    "    texto = leer_archivo(link_doc).lower()\n",
    "    json_str = separar_bloques(texto)\n",
    "    \n",
    "    json_data = json.loads(json_str)\n",
    "    return json_data\n",
    "    \n"
   ],
   "id": "cb48c23bab3662af",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tratamiento de json por documento",
   "id": "453f92ce714917e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:16:55.238428Z",
     "start_time": "2024-05-02T03:16:55.231913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "id": "43ff30063cd8e63e",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:30:21.660864Z",
     "start_time": "2024-05-02T03:30:21.649218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenizacion_texto(texto):\n",
    "    stop_words = stopwords.words('english')\n",
    "    texto = texto.lower()\n",
    "    tokens = word_tokenize(texto)\n",
    "    text_filtrado = [word for word in tokens if not word in stop_words]\n",
    "    return text_filtrado"
   ],
   "id": "f543e7a62677a5d7",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:41:14.816605Z",
     "start_time": "2024-05-02T01:41:14.803308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def json_doc_postulante(json_postulante):\n",
    "    json_postulante_habilidades = json_postulante['habilidades']\n",
    "    json_postulante_experiencia = json_postulante['experiencia_laboral']\n",
    "    tokenizado_habilidades = tokenizacion_texto(json_postulante_habilidades)\n",
    "    tokenizado_expeciencia = tokenizacion_texto(json_postulante_experiencia)\n",
    "    print(tokenizado_habilidades)"
   ],
   "id": "f7d92609c5a6e997",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T05:26:34.722954Z",
     "start_time": "2024-05-02T05:26:33.488131Z"
    }
   },
   "cell_type": "code",
   "source": "from diccionario_similitud import *",
   "id": "abe06a91e1217384",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'entropy' from 'scipy.stats' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[130], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdiccionario_similitud\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Recursos-Humanos-reclutamiento-por-medio-de-cv-usando-NLP\\Analisis\\diccionario_similitud.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Word2Vec\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mopenpyxl\u001B[39;00m\n\u001B[0;32m      4\u001B[0m ruta_modelo_experiencia_laboral \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../Modelos/experiencia_laboral.model\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\__init__.py:11\u001B[0m\n\u001B[0;32m      7\u001B[0m __version__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m4.3.0\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[0;32m     14\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgensim\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m logger\u001B[38;5;241m.\u001B[39mhandlers:  \u001B[38;5;66;03m# To ensure reload() doesn't add another one\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\corpora\\__init__.py:6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mThis package contains implementations of various streaming corpus I/O format.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# bring corpus classes directly into package namespace, to save some typing\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mindexedcorpus\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IndexedCorpus  \u001B[38;5;66;03m# noqa:F401 must appear before the other classes\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmmcorpus\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MmCorpus  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbleicorpus\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BleiCorpus  \u001B[38;5;66;03m# noqa:F401\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\corpora\\indexedcorpus.py:14\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m interfaces, utils\n\u001B[0;32m     16\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mIndexedCorpus\u001B[39;00m(interfaces\u001B[38;5;241m.\u001B[39mCorpusABC):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\interfaces.py:19\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03m\"\"\"Basic interfaces used across the whole Gensim package.\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03mThese interfaces are used for building corpora, model transformation and similarity queries.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     14\u001B[0m \n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils, matutils\n\u001B[0;32m     22\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCorpusABC\u001B[39;00m(utils\u001B[38;5;241m.\u001B[39mSaveLoad):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\gensim\\matutils.py:19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m entropy\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinalg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_blas_funcs, triu\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinalg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlapack\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_lapack_funcs\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'entropy' from 'scipy.stats' (unknown location)"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Asignacion de Puntaje",
   "id": "b6145878c2ffad6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:41:16.603763Z",
     "start_time": "2024-05-02T01:41:16.597311Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8152a406b400cd8",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:41:16.812231Z",
     "start_time": "2024-05-02T01:41:16.806168Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d8367d36faacfff7",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:41:16.919312Z",
     "start_time": "2024-05-02T01:41:16.912052Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d52fcb88bd08c01c",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graficas de rendimiento",
   "id": "ed42f0bbac1e281b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Resultados",
   "id": "fd3b118a2229f46f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ejecucion",
   "id": "e382560cc7e630ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:41:17.545029Z",
     "start_time": "2024-05-02T01:41:17.529036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def procesar_archivos(ruta_txt):\n",
    "    archivos = os.listdir(ruta_txt)\n",
    "    for archivo in archivos:\n",
    "        ruta_archivo = os.path.join(ruta_txt, archivo)\n",
    "        try:            \n",
    "            json_postulante = convert_doc_to_json(ruta_archivo)\n",
    "            json_doc_postulante(json_postulante)            \n",
    "        except Exception as e:\n",
    "            print(\"Error al insertar datos:\", e)"
   ],
   "id": "d9b94fe5d7325c79",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:41:18.133285Z",
     "start_time": "2024-05-02T01:41:18.003191Z"
    }
   },
   "cell_type": "code",
   "source": "procesar_archivos(ruta_txt)",
   "id": "6c52ecda7e6e2b47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abilities', '>', 'strong', 'customer', 'service', 'focus', '.', '>', 'excellent', 'communication', 'skills', '.', '>', 'ability', 'interact', 'wide', 'range', 'team', 'members', 'demands', '.', 'key', 'experience', '>', 'extensive', 'experience', 'engineering', 'project', 'management', '.', '>', 'engineering', 'forte', 'electrical', 'electronics', '.', '>', 'expert', 'ready-mix', 'plant', 'operations', 'maintenance', 'electrical', 'construction', 'projects', '.', '>', 'self', 'motivated', 'professional', ',', 'capable', 'working', 'independently', 'part', 'team', '.']\n",
      "['skills', ':', 'e', 'platforms', ':', 'windows', '98', ',', '2000', ',', 'windows', 'xp', ',', 'vista', ',', 'windows7', '&', '8.', 'e', 'knowledge', 'auto', 'cad', ',', 'pro/e', '(', 'creo', ')', '.', 'â¢', '*', 'project', 'undertaken', ':', 'e', 'project', 'nuame-regenerative', 'braking', 'system', '.', 'page', '1', '2', 'e', 'project', 'duration-1', 'year', '.', 'â€œ', '*']\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:31:04.227109Z",
     "start_time": "2024-05-02T01:31:04.220082Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "637be834dafac61d",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:27:46.078217Z",
     "start_time": "2024-05-02T01:27:46.071922Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "61e1f01bd8a84655",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.605001Z",
     "start_time": "2024-04-30T11:48:54.603283Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4c150a6411f5557a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.607748Z",
     "start_time": "2024-04-30T11:48:54.605940Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d2ca2b910df6f923",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.610446Z",
     "start_time": "2024-04-30T11:48:54.608718Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b57ba5623723a8f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.613617Z",
     "start_time": "2024-04-30T11:48:54.611700Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e8aa6255e81c3306",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.616274Z",
     "start_time": "2024-04-30T11:48:54.614605Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b1efffdef192a4dd",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.618879Z",
     "start_time": "2024-04-30T11:48:54.617220Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "209cc7499daf3508",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.621562Z",
     "start_time": "2024-04-30T11:48:54.619869Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1c39589e8aa042f8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.625721Z",
     "start_time": "2024-04-30T11:48:54.623279Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "70e1edf0f55808b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T11:48:54.628926Z",
     "start_time": "2024-04-30T11:48:54.626801Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "11f5dc9a38549840",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5227bd3b72251460"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
